{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This code assumes that you already have your dimensionally-reduced UKBB data. It is meant primarily to organize your datasets and create visualizations and carry out statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Interactive HTML tools\n",
    "from ipywidgets import interact\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure, show, save, output_notebook, output_file\n",
    "\n",
    "# Machine-learning and dimensionality reduction tools\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import PC data\n",
    "Import the principal components. The main reason is to get the IDs for every individual lined up. Generally, you don't want to run dimension reduction on a dataset this size in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "\n",
    "# Define the files we'll be using\n",
    "pc_file = 'ukbb_pca_only'\n",
    "pc_path = os.path.join(data_dir, pc_file)\n",
    "\n",
    "# Import PC data. This data must be converted to an array.\n",
    "with open(pc_path) as pc:\n",
    "    pca_contents = pc.readlines()\n",
    "\n",
    "pca_data = []\n",
    "\n",
    "for pc in pca_contents[1:]:\n",
    "    pca_data.append(pc.split()[3:len(pc)])\n",
    "\n",
    "# Purely numeric values of PCA\n",
    "pca_data_array = np.array(pca_data).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import auxiliary data\n",
    "Gradually build up our data frame. Add ethnicity, geographic data, various phenotypes. Done in an inelegant but functional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux_data_dir = '/Users/alex/Documents/Ethnicity'\n",
    "\n",
    "# Import the auxiliary data and reduce it to the ethnicity information and the IDs\n",
    "# Note we import both ethnicities that people give us, though there are very few differences.\n",
    "ukbb_aux_df = pd.read_csv('/Users/alex/Documents/Ethnicity/UKBB_pheno/ukb4940.csv')\n",
    "ukbb_aux_df = ukbb_aux_df.filter(['eid','21000-0.0','21000-1.0'])\n",
    "\n",
    "# Create a string ID to match PCA for joining\n",
    "ukbb_aux_df['eid_str'] = ukbb_aux_df['eid'].apply(str)\n",
    "ukbb_aux_df.columns=['eid','eth1','eth2','eid_str']\n",
    "\n",
    "# Take care of NA values\n",
    "ukbb_aux_df['eth1'] = ukbb_aux_df['eth1'].fillna(-9).astype(int)\n",
    "ukbb_aux_df.loc[(ukbb_aux_df['eth2'].isnull()==True), 'eth2'] = ukbb_aux_df.loc[(ukbb_aux_df['eth2'].isnull()==True), 'eth1']\n",
    "ukbb_aux_df['eth2'] = ukbb_aux_df['eth2'].fillna(-9).astype(int)\n",
    "\n",
    "# Convert ethnicities to strings (digits represent categories)\n",
    "ukbb_aux_df['eth1_str'] = ukbb_aux_df['eth1'].astype(str)\n",
    "ukbb_aux_df['eth2_str'] = ukbb_aux_df['eth2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import geography data\n",
    "# The grid coordinate data are provided in the British National Grid (i.e. OSGB1936) projection.\n",
    "# OSGB1936 is the Ordnance Survey National Grid geographic reference system\n",
    "# See https://epsg.io/map#srs=27700 for a demo\n",
    "geo_file = 'eid_df22006_df129north_df130east.mer'\n",
    "\n",
    "ukbb_geo_df = pd.read_csv(os.path.join(aux_data_dir,geo_file))\n",
    "ukbb_geo_df.columns=['eid','genetic_grouping','northing','easting']\n",
    "ukbb_geo_df['northing_orig']=ukbb_geo_df['northing']\n",
    "ukbb_geo_df['easting_orig']=ukbb_geo_df['easting']\n",
    "\n",
    "\n",
    "mask = ukbb_geo_df.northing.isnull()\n",
    "col_name = 'northing'\n",
    "ukbb_geo_df.loc[mask, col_name] = 0\n",
    "\n",
    "mask = ukbb_geo_df.easting.isnull()\n",
    "col_name = 'easting'\n",
    "ukbb_geo_df.loc[mask, col_name] = 0\n",
    "\n",
    "mask = ukbb_geo_df.northing < 0\n",
    "col_name = 'northing'\n",
    "ukbb_geo_df.loc[mask, col_name] = 0\n",
    "\n",
    "mask = ukbb_geo_df.easting < 0\n",
    "col_name = 'easting'\n",
    "ukbb_geo_df.loc[mask, col_name] = 0\n",
    "\n",
    "ukbb_geo_df['northing']=ukbb_geo_df['northing']/max(ukbb_geo_df['northing'])\n",
    "ukbb_geo_df['easting']=ukbb_geo_df['easting']/max(ukbb_geo_df['easting'])\n",
    "ukbb_geo_df['eid_str_geo'] = ukbb_geo_df['eid'].astype(str)\n",
    "\n",
    "# Fill NaN values\n",
    "ukbb_geo_df['northing_filled'] = ukbb_geo_df['northing_orig'].fillna(0)\n",
    "ukbb_geo_df['easting_filled'] = ukbb_geo_df['easting_orig'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue dealing with NaN values\n",
    "northing_orig = ukbb_geo_df['northing_orig'].values\n",
    "northing_orig = northing_orig[np.isnan(northing_orig)==False]\n",
    "\n",
    "easting_orig = ukbb_geo_df['easting_orig'].values\n",
    "easting_orig = easting_orig[np.isnan(easting_orig)==False]\n",
    "\n",
    "northing = ukbb_geo_df['northing'].values\n",
    "northing = northing[northing>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the PCA IDs as a pandas data frame\n",
    "with open(pc_path) as pc:\n",
    "    pca_contents = pc.readlines()\n",
    "\n",
    "pca_data_aux = []\n",
    "\n",
    "for pc in pca_contents[1:]:\n",
    "    pca_data_aux.append(pc.split()[0:2])\n",
    "\n",
    "ukbb_pca_df = pd.DataFrame.from_records(pca_data_aux)\n",
    "ukbb_pca_df.columns = ['FID','IID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the ethnicities to the PCA IDs\n",
    "ukbb_df_joined = ukbb_pca_df.merge(ukbb_aux_df, left_on='IID', right_on='eid_str', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the geographic values\n",
    "ukbb_df_joined2 = ukbb_df_joined.merge(ukbb_geo_df, left_on='IID', right_on='eid_str_geo', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some weird missing values still around\n",
    "ukbb_df_joined2['easting_filled'] = ukbb_df_joined2['easting_filled'].fillna(0)\n",
    "ukbb_df_joined2['northing_filled'] = ukbb_df_joined2['northing_filled'].fillna(0)\n",
    "ukbb_df_joined2['eth1_str'] = ukbb_df_joined2['eth1_str'].fillna('-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas may spit out a warning here but it doesn't seem to make a difference\n",
    "ukbb_geo_colours = ukbb_df_joined2[['northing','easting']]\n",
    "\n",
    "# Fix rare NaNs (where there was no data for individuals)\n",
    "ukbb_geo_colours['northing'] = ukbb_geo_colours['northing'].fillna(0).astype(float)\n",
    "ukbb_geo_colours['easting'] = ukbb_geo_colours['easting'].fillna(0).astype(float)\n",
    "\n",
    "ukbb_geo_colours = ukbb_geo_colours.values.tolist()\n",
    "\n",
    "# Create a list of the original values too\n",
    "ukbb_geo_colours_orig = ukbb_df_joined2[['northing_filled','easting_filled']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colours and labelling\n",
    "The stuff below here is for labelling and colouring of ethnicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put together a dict of values\n",
    "# Taken from: http://biobank.ctsu.ox.ac.uk/crystal/coding.cgi?id=1001\n",
    "# This dictionary covers all given ethnicities and their UKBB codes\n",
    "ukbb_eth_dict = {\n",
    "    '1':'White',\n",
    "    '1001':'British',\n",
    "    '1002':'Irish',\n",
    "    '1003':'Any other white background',\n",
    "    '2':'Mixed',\n",
    "    '2001':'White and Black Caribbean',\n",
    "    '2002':'White and Black African',\n",
    "    '2003':'White and Asian',\n",
    "    '2004':'Any other mixed background',\n",
    "    '3':'Asian or Asian British',\n",
    "    '3001':'Indian',\n",
    "    '3002':'Pakistani',\n",
    "    '3003':'Bangladeshi',\n",
    "    '3004':'Any other Asian background',\n",
    "    '4':'Black or Black British',\n",
    "    '4001':'Caribbean',\n",
    "    '4002':'African',\n",
    "    '4003':'Any other Black background',\n",
    "    '5':'Chinese',\n",
    "    '6':'Other ethnic group',\n",
    "    '-1':'Do not know',\n",
    "    '-3':'Prefer not to answer',\n",
    "    '-9':'Not available'\n",
    "}\n",
    "\n",
    "# Child categories of ethnicities\n",
    "ukbb_dict_child = {\n",
    "    '1001':'British',\n",
    "    '1002':'Irish',\n",
    "    '1003':'Any other white background',\n",
    "    '2001':'White and Black Caribbean',\n",
    "    '2002':'White and Black African',\n",
    "    '2003':'White and Asian',\n",
    "    '2004':'Any other mixed background',\n",
    "    '3001':'Indian',\n",
    "    '3002':'Pakistani',\n",
    "    '3003':'Bangladeshi',\n",
    "    '3004':'Any other Asian background',\n",
    "    '4001':'Caribbean',\n",
    "    '4002':'African',\n",
    "    '4003':'Any other Black background',\n",
    "    '5':'Chinese',\n",
    "    '6':'Other ethnic group',\n",
    "    '-1':'Do not know',\n",
    "    '-3':'Prefer not to answer',\n",
    "    '-9':'Not available'    \n",
    "}\n",
    "\n",
    "# Parent categories of ethnicities\n",
    "ukbb_dict_parent = {\n",
    "    '1':'White',\n",
    "    '2':'Mixed',\n",
    "    '3':'Asian or Asian British',\n",
    "    '4':'Black or Black British',\n",
    "    '5':'Chinese',\n",
    "    '6':'Other ethnic group',\n",
    "    '-':'NA'\n",
    "}\n",
    "\n",
    "# Secondary relationship between parent-child ethnicities\n",
    "# Keys are parent ethnicities (e.g. 'Asian or Asian British') and value is a list of child ethnicities ('Indian', etc)\n",
    "ukbb_eth_dict_parent = defaultdict(list)\n",
    "\n",
    "for key,value in ukbb_eth_dict.items():\n",
    "    parent = key[0]\n",
    "    \n",
    "    if key not in ['1','2','3','4']:\n",
    "        try:\n",
    "            ukbb_eth_dict_parent[ukbb_dict_parent[parent]].append(value)\n",
    "        except KeyError:\n",
    "            ukbb_eth_dict_parent[ukbb_dict_parent[parent]] = value\n",
    "            \n",
    "# Reversed dictionaries\n",
    "ukbb_dict_child_rev = dict()\n",
    "\n",
    "for key, value in ukbb_dict_child.items():\n",
    "    ukbb_dict_child_rev.update({value: key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_eth_dict_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Markers used to plot points\n",
    "markers_dict = {\n",
    "    'White':'o',\n",
    "    'Mixed':'*',\n",
    "    'Asian or Asian British':'P',\n",
    "    'Black or Black British':'P',\n",
    "    'Chinese':'^',\n",
    "    'Other ethnic group':'s',\n",
    "    'NA':'X'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of ethnic backgrounds for multiple testing (used in boxplots)\n",
    "eth_list = ['British','Irish','Any other white background','White and Black African','White and Black Caribbean',\\\n",
    "            'White and Asian','African','Caribbean','Any other Black background','Chinese','Indian','Pakistani',\\\n",
    "            'Bangladeshi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the indices by category\n",
    "population_by_individual = defaultdict(int)\n",
    "individual_by_population = defaultdict(list)\n",
    "indices_of_population_members = defaultdict(list)\n",
    "\n",
    "for k in ukbb_eth_dict.keys():\n",
    "    temp_list = ukbb_df_joined[ukbb_df_joined['eth1_str']==k].index.values.tolist()\n",
    "    indices_of_population_members[ukbb_eth_dict[k]] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Colour palette selection here. Originally there was a systematic method but it was much easier to do it manually.\n",
    "from bokeh.palettes import Blues, BuGn, Category10, Category20, Category20b, Category20c, Plasma256, PuBuGn, \\\n",
    "Purples, RdPu, Reds, Spectral, YlOrBr\n",
    "\n",
    "# PARENT - Child colours\n",
    "# WHITE - British, Irish, Other\n",
    "# MIXED - W&B Caribbean, W&B African, W&Asian, Other\n",
    "# ASIAN/ASIAN BRITISH - Indian, Pakistani, Bangladeshi, Other\n",
    "# CHINESE\n",
    "# OTHER\n",
    "# DK, NO ANSWER, N/A\n",
    "\n",
    "color_list = Category20b[20]+Spectral[11]\n",
    "\n",
    "counter = 0\n",
    "# Set up the colours (matplotlib tab20c)\n",
    "color_dict_ukbb = {}\n",
    "\n",
    "for pop in ukbb_eth_dict_parent:\n",
    "    counter=0\n",
    "    \n",
    "    # White population is blue-greenish\n",
    "    if pop=='White':\n",
    "        color_dict_ukbb[pop]=PuBuGn[9][counter]\n",
    "        counter+=1\n",
    "        for subpop in ukbb_eth_dict_parent[pop]:\n",
    "            color_dict_ukbb[subpop] = PuBuGn[9][counter*2]\n",
    "            counter+=1\n",
    "    # Mixed population is green\n",
    "    elif pop=='Mixed':\n",
    "        color_dict_ukbb[pop]=BuGn[9][counter]\n",
    "        color_dict_ukbb['White and Black Caribbean']=Category10[3][-2] # Orange\n",
    "        color_dict_ukbb['White and Black African']=Category10[4][-1] # Red\n",
    "        color_dict_ukbb['White and Asian']=Category10[5][-1] # Purple\n",
    "        color_dict_ukbb['Any other mixed background']=Category10[3][-1] # Green\n",
    "    elif pop in ['Asian or Asian British']:\n",
    "        color_dict_ukbb[pop]=Purples[9][0] # Dark purple\n",
    "        color_dict_ukbb['Indian']=RdPu[9][0] # Dark red-purple\n",
    "        color_dict_ukbb['Pakistani']=RdPu[9][2] # More pinkish dark red-purple\n",
    "        color_dict_ukbb['Bangladeshi']=RdPu[9][4] # Even more pinkish dark red-purple\n",
    "        color_dict_ukbb['Any other Asian background']=RdPu[9][-3] # Lighter red-purple\n",
    "    elif pop in ['Chinese']:\n",
    "        color_dict_ukbb[pop]=Category20[13][-1]\n",
    "        counter+=1\n",
    "    # Black population is yellow/orange/brown\n",
    "    elif pop=='Black or Black British':\n",
    "        color_dict_ukbb['Black or Black British']=YlOrBr[9][4] # Hazy orange\n",
    "        color_dict_ukbb['Caribbean']=Reds[9][4] # Hazy red\n",
    "        color_dict_ukbb['African']=Reds[9][0] # Deep red\n",
    "        color_dict_ukbb['Any other Black background']=YlOrBr[9][-4] # Lighter Hazy orange\n",
    "    # Other ethnic groups are some variety of grey\n",
    "    elif pop=='Other ethnic group':\n",
    "        for subpop in ukbb_eth_dict_parent[pop]:\n",
    "            color_dict_ukbb[subpop] = Category20c[20][16+counter]\n",
    "            counter+=1\n",
    "    elif pop=='NA':\n",
    "        for subpop in ukbb_eth_dict_parent[pop]:\n",
    "            color_dict_ukbb[subpop] = Category20c[20][17+counter]\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add height\n",
    "Split by sex and adjust height for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 0: Import datasets and merge them (horrible mess of code)\n",
    "pheno_dir = '/Volumes/Stockage/alex/ukbb_phenos'\n",
    "height_file = 'Height.pheno'\n",
    "covar_file = 'ukb4940.csv'\n",
    "\n",
    "# File of covariates\n",
    "ukbb_covar = pd.read_csv(os.path.join(pheno_dir, covar_file))[['eid','31-0.0']]\n",
    "ukbb_covar.columns = ['eid_covar', 'sex'] # (0 = F, 1 = M)\n",
    "ukbb_covar['eid_covar']=ukbb_covar['eid_covar'].astype(str)\n",
    "ukbb_covar['sex']=ukbb_covar['sex'].astype(str)\n",
    "\n",
    "# Read in the UKBB height phenotype data. We need to join this to the main UKBB dataset to get indexing right.\n",
    "ukbb_pheno_height = pd.read_csv(os.path.join(pheno_dir,height_file), sep=' ')\n",
    "ukbb_pheno_height['FID']=ukbb_pheno_height['FID'].astype(str)\n",
    "ukbb_pheno_height['IID']=ukbb_pheno_height['IID'].astype(str)\n",
    "\n",
    "ukbb_pheno_height.columns=['FID_height','IID_height','Height']\n",
    "\n",
    "ukbb_pheno_joined = ukbb_df_joined2.merge(ukbb_pheno_height, left_on='IID', right_on='IID_height', how='left')\n",
    "ukbb_pheno_joined = ukbb_pheno_joined.merge(ukbb_covar, left_on='IID',right_on='eid_covar', how='left')\n",
    "\n",
    "ukbb_pheno_age = pd.read_csv(os.path.join(pheno_dir, covar_file))[['eid','21003-0.0']]\n",
    "ukbb_pheno_age.columns=['EID_age','age']\n",
    "ukbb_pheno_age['EID_age']=ukbb_pheno_age['EID_age'].astype(str)\n",
    "ukbb_pheno_age['age'] = ukbb_pheno_age['age'].fillna(0)\n",
    "\n",
    "ukbb_pheno_joined = ukbb_pheno_joined.merge(ukbb_pheno_age, left_on='FID',right_on='EID_age', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Split by sex(0=F)\n",
    "sex_list = ukbb_pheno_joined['sex'].values.tolist()\n",
    "indices_of_population_sex = defaultdict(list)\n",
    "\n",
    "for sex in ['0','1']:\n",
    "    temp_list = ukbb_pheno_joined[ukbb_pheno_joined['sex']==sex].index.values.tolist()\n",
    "    indices_of_population_sex[sex] = temp_list\n",
    "\n",
    "ukbb_pheno_joined_f = ukbb_pheno_joined.iloc[indices_of_population_sex['0']]\n",
    "ukbb_pheno_joined_m = ukbb_pheno_joined.iloc[indices_of_population_sex['1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Drop missing values\n",
    "ukbb_pheno_joined_f=ukbb_pheno_joined_f[ukbb_pheno_joined_f.Height>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Regression\n",
    "X = ukbb_pheno_joined_f[[\"age\"]]\n",
    "y = ukbb_pheno_joined_f[[\"Height\"]]\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "residuals_f = y - lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ukbb_pheno_joined_f['Height_res'] = residuals_f\n",
    "ukbb_pheno_joined_f['Age_coeff'] = lm.coef_[0][0]\n",
    "ukbb_pheno_joined_f['int'] = lm.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do steps 2 and 3 for males\n",
    "ukbb_pheno_joined_m=ukbb_pheno_joined_m[ukbb_pheno_joined_m.Height>0]\n",
    "\n",
    "X = ukbb_pheno_joined_m[[\"age\"]]\n",
    "y = ukbb_pheno_joined_m[[\"Height\"]]\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "residuals_m = y - lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ukbb_pheno_joined_m['Height_res'] = residuals_m\n",
    "ukbb_pheno_joined_m['Age_coeff'] = lm.coef_[0][0]\n",
    "ukbb_pheno_joined_m['int'] = lm.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4a: Combine the two datasets from above\n",
    "ukbb_pheno_height_res = pd.concat([ukbb_pheno_joined_f, ukbb_pheno_joined_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4b: Get the IID-residual height and merge\n",
    "ukbb_pheno_joined_height_res = ukbb_pheno_joined.merge(ukbb_pheno_height_res[['FID_height','Height_res','Age_coeff','int']],how='left',left_on='FID',right_on='FID_height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ukbb_pheno_joined_height_res['Height_age']=ukbb_pheno_joined_height_res['Height']-ukbb_pheno_joined_height_res['age']*ukbb_pheno_joined_height_res['Age_coeff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add FEV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import asthma FEV data and format/name columns so they work\n",
    "asthma_dir = '/Volumes/Stockage/alex/ukbb_phenos'\n",
    "asthma_file = 'ukb5602_filt_lung1.csv'\n",
    "\n",
    "ukbb_asthma = pd.read_csv(os.path.join(asthma_dir, asthma_file),delimiter=' ')\n",
    "ukbb_asthma.columns=['eid_asthma'] + [ch.replace('.','_').replace('-','_') for ch in ukbb_asthma.columns.tolist()[1:]]\n",
    "ukbb_asthma['eid_asthma'] = ukbb_asthma['eid_asthma'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join to existing dataset\n",
    "ukbb_pheno_joined_fev = ukbb_pheno_joined.merge(ukbb_asthma[['eid_asthma','3063_0_0']],how='left',\n",
    "                                                left_on='eid_str',right_on='eid_asthma')\n",
    "ukbb_pheno_joined_fev2 = ukbb_pheno_joined_fev.merge(ukbb_pheno_height_res[['eid_covar','Height_res']],how='left',\n",
    "                                                left_on='eid_asthma',right_on='eid_covar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add other phenotypes\n",
    "Blood phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_dir = '/Volumes/Stockage/alex/ukbb_phenos'\n",
    "\n",
    "# Phenotype data is split among several different files\n",
    "pheno_file = 'ukb7683.csv'\n",
    "\n",
    "# Fields we wish to select\n",
    "fields = ['eid','30000-0.0','30150-0.0','30160-0.0','30190-0.0','30120-0.0','30140-0.0','30010-0.0']\n",
    "\n",
    "# The names are uninformative so change them\n",
    "fields_names = ['eid_blood','leukocyte_count','eosinophill_count','basophill_count','monocyte_pct','lymophocyte_count'\\\n",
    "               ,'neutrophill_count','erythrocyte_count']\n",
    "\n",
    "pheno_blood = pd.read_csv(os.path.join(pheno_dir, pheno_file), usecols=fields)\n",
    "pheno_blood.columns=fields_names\n",
    "\n",
    "# Also convert the IDs to strings for the eventual join\n",
    "pheno_blood['eid_blood']=pheno_blood['eid_blood'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join to existing data frame.\n",
    "ukbb_pheno_joined_height_res_blood = pd.merge(ukbb_pheno_joined_fev2,pheno_blood,left_on='eid_str',\n",
    "                                              right_on='eid_blood',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some text descriptors for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ukbb_eth_df = pd.DataFrame(list(ukbb_eth_dict.items()), columns=['eth_code','eth_txt'])\n",
    "# Join text description of ethnicity\n",
    "ukbb_pheno_joined_height_res_blood_2 = pd.merge(ukbb_pheno_joined_height_res_blood, ukbb_eth_df, left_on='eth1_str', \\\n",
    "                                              right_on='eth_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a 2D projection and generate an image\n",
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "proj_name = 'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511'\n",
    "out_dir = '/Volumes/Stockage/alex/ukbb_images'\n",
    "proj = np.loadtxt(os.path.join(proj_dir, proj_name))\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "for pop in ukbb_eth_dict_parent:\n",
    "    if pop in ['White','Mixed','Asian or Asian British','Black or Black British']:\n",
    "        temp_proj = proj[indices_of_population_members[pop],:]\n",
    "        ax.plot(temp_proj[:,0], temp_proj[:,1],'.',label=pop,color=color_dict_ukbb[pop])\n",
    "\n",
    "    for subpop in ukbb_eth_dict_parent[pop]:\n",
    "        temp_proj = proj[indices_of_population_members[subpop],:]\n",
    "        ax.plot(temp_proj[:,0], temp_proj[:,1],markers_dict[pop],label=subpop,color=color_dict_ukbb[subpop])\n",
    "\n",
    "ax.legend(ncol=1,loc='center left', bbox_to_anchor=(1,0.5), fontsize=20)\n",
    "\n",
    "fig.savefig(os.path.join(out_dir, fname+'_eth.jpeg'),format='jpeg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is the same, but loops through and finds all 2D UMAP and tSNE projections and plots them (i.e. it does multiple plots rather than selecting one). This is based on my naming conventions entirely so YMMV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "out_dir = '/Volumes/Stockage/alex/ukbb_images'\n",
    "\n",
    "# Loop through every file in specified directory\n",
    "for fname in os.listdir(proj_dir):\n",
    "    # Only plot UMAP and TSNE projections in 2D\n",
    "    if 'UMAP' not in fname and 'TSNE' not in fname and 'tsne' not in fname and not 'NC3' in fname \\\n",
    "    or os.path.isdir(os.path.join(proj_dir,fname)):\n",
    "        continue\n",
    "    else:   \n",
    "        # Don't overwrite existing plots\n",
    "        if not os.path.exists(os.path.join(out_dir, fname+'_eth.jpeg')):\n",
    "            print('Beginning plotting for ' + fname)\n",
    "            \n",
    "            proj = np.loadtxt(os.path.join(proj_dir, fname))\n",
    "            fig = plt.figure(figsize=(50,50))\n",
    "            ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "            for pop in ukbb_eth_dict_parent:\n",
    "                if pop in ['White','Mixed','Asian or Asian British','Black or Black British']:\n",
    "                    temp_proj = proj[indices_of_population_members[pop],:]\n",
    "                    ax.scatter(temp_proj[:,0], temp_proj[:,1],label=pop,color=color_dict_ukbb[pop],alpha=0.6)\n",
    "\n",
    "                for subpop in ukbb_eth_dict_parent[pop]:\n",
    "                    temp_proj = proj[indices_of_population_members[subpop],:]\n",
    "                    if subpop in ['Other ethnic group','Do not know']:\n",
    "                        ax.scatter(temp_proj[:,0], temp_proj[:,1],marker=markers_dict[pop],label=subpop,facecolors='none',\n",
    "                                edgecolors=color_dict_ukbb[subpop],alpha=0.6)\n",
    "                    else:\n",
    "                        ax.scatter(temp_proj[:,0], temp_proj[:,1],marker=markers_dict[pop],label=subpop,color=color_dict_ukbb[subpop],alpha=0.6)\n",
    "\n",
    "            ax.legend(ncol=4,loc='lower center', bbox_to_anchor=(0.4,-0.12), fontsize=40,markerscale=10)\n",
    "\n",
    "            fig.savefig(os.path.join(out_dir, fname+'_eth.jpeg'),format='jpeg')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (geography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some default values for easting and northing where it's missing\n",
    "# The values themselves aren't used as missing data is plotted as transparent points\n",
    "# We assign a value so it doesn't get binned or break the indexing later.\n",
    "easting_mean = np.mean(easting_orig)\n",
    "northing_mean = np.mean(northing_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do KD-tree nearest neighbour imputation.\n",
    "\n",
    "Algorithm for KD stuff. For each point, grab the phenotype measurement from ones of its k nearest neighbours and just plot that.\n",
    "1. Reduce dataset to observations that have data\n",
    "2. Select point\n",
    "3. Find neighbours\n",
    "3. Randomly choose neighbour\n",
    "5. Impute whatever value we're looking at (in the case of geography it's the geo coords/colourings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the projection and subset it to just those that have geographical data\n",
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "file = 'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511'\n",
    "\n",
    "temp_proj = np.loadtxt(os.path.join(proj_dir,file))\n",
    "\n",
    "# indices of points that have geographical coordinates\n",
    "has_data = ukbb_df_joined2.loc[(np.isnan(ukbb_df_joined2.northing_orig)==False)].index\n",
    "\n",
    "# Subset coordinate array such that it's only observations with data\n",
    "temp_proj_geo = temp_proj[has_data]\n",
    "\n",
    "# Make it into a dataframe and make a list of the coordinates, where they exist\n",
    "has_data_df = ukbb_df_joined2.iloc[has_data]\n",
    "has_data_coords = has_data_df[['northing_filled','easting_filled']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create K-D tree object\n",
    "kd_obj = scipy.spatial.KDTree(temp_proj_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables:\n",
    "* round_val (position to which we wish to round)\n",
    "* sd (standard deviation, in metres, of the noise we add to each point)\n",
    "* base (value to which we wish to round, e.g. nearest 10, nearest 25, in metres)\n",
    "\n",
    "These will be reflected in the file name at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test out permutations with nearest neighbours. We'll swap in values of randomly select neighbours.\n",
    "# Those with zero values are invalid, so we make them invisible (alpha value of zero)\n",
    "temp_colours_ns = []\n",
    "temp_colours_ew = []\n",
    "\n",
    "temp_alpha = []\n",
    "\n",
    "ns_min = 100000\n",
    "ns_max = 700000\n",
    "ew_min = 200000\n",
    "ew_max = 600000\n",
    "alpha_vals = 0.6\n",
    "\n",
    "round_val = -4\n",
    "sd=50000\n",
    "base=25000 # round to nearest however many thousand metres\n",
    "\n",
    "for u in has_data_coords:\n",
    "    no_geo = False\n",
    "    # Set alpha to zero for unknown geo values\n",
    "    if u[0]<=0 or u[1]<=0:\n",
    "        no_geo = True\n",
    "        temp_alpha.append(np.float(0))\n",
    "        temp_colours_ns.append((northing_mean))\n",
    "        temp_colours_ew.append((easting_mean))\n",
    "\n",
    "    if no_geo==False:\n",
    "        if u[0] < ns_min:\n",
    "            temp_colours_ns.append(ns_min)\n",
    "        elif u[0] > ns_max:\n",
    "            temp_colours_ns.append(ns_max)\n",
    "        else:\n",
    "            temp_colours_ns.append(round(u[0] + np.random.normal(0,sd),round_val))\n",
    "        \n",
    "        if u[1] < ew_min:\n",
    "            temp_colours_ew.append(ew_min)\n",
    "        elif u[1] > ew_max:\n",
    "            temp_colours_ew.append(ew_max)\n",
    "        else:\n",
    "            temp_colours_ew.append(round(u[1] + np.random.normal(0,sd),round_val))\n",
    "                        \n",
    "        temp_alpha.append(np.float(alpha_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rounding for labels \n",
    "temp_colours_ns = [t/1000 for t in temp_colours_ns]\n",
    "temp_colours_ew = [t/1000 for t in temp_colours_ew]\n",
    "\n",
    "ns_min = ns_min/1000\n",
    "ns_max = ns_max/1000\n",
    "ew_min = ew_min/1000\n",
    "ew_max = ew_max/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random seed and store it for reproducibility\n",
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st0 = np.random.get_state()\n",
    "\n",
    "temp_colours_permuted_ns = []\n",
    "temp_colours_permuted_ew = []\n",
    "index_list = []\n",
    "\n",
    "# Now that we have our colouring values we can sample them randomly (since neighbours exist now)\n",
    "for t in range(0, temp_proj_geo.shape[0]):\n",
    "    # Randomly select an index from a neighbour\n",
    "    nn_index = np.random.choice(kd_obj.query(temp_proj_geo[t],10)[1][1:])\n",
    "    index_list.append(nn_index)\n",
    "    temp_colours_permuted_ns.append(temp_colours_ns[nn_index])\n",
    "    temp_colours_permuted_ew.append(temp_colours_ew[nn_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_ns = matplotlib.colors.Normalize(vmin=ns_min, vmax=ns_max, clip=False)\n",
    "norm_ew = matplotlib.colors.Normalize(vmin=ew_min, vmax=ew_max, clip=False)\n",
    "mapper_ns = cm.ScalarMappable(norm=norm_ns, cmap=cm.coolwarm_r)\n",
    "mapper_ew = cm.ScalarMappable(norm=norm_ew, cmap=cm.spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colours_ns = []\n",
    "colours_ew = []\n",
    "    \n",
    "for i in range(0, temp_proj_geo.shape[0]):\n",
    "    colours_ns.append(mapper_ns.to_rgba(temp_colours_permuted_ns[i], alpha=temp_alpha[i]))\n",
    "    colours_ew.append(mapper_ew.to_rgba(temp_colours_permuted_ew[i], alpha=temp_alpha[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not totally sure why I have to do this but here we are\n",
    "mapper_ns_temp = mapper_ns\n",
    "mapper_ew_temp = mapper_ew\n",
    "\n",
    "mapper_ns_temp._A = []\n",
    "mapper_ew_temp._A = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a timestamp to relate images to their random imputation\n",
    "tstamp = ''.join([str(t) for t in time.gmtime()[0:6]])\n",
    "\n",
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "img_dir = '/Volumes/Stockage/alex/ukbb_images/other/sandbox'\n",
    "suffix = '_permuted_10nn_sd' + str(sd) + '_base' + str(base)\n",
    "file = 'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511'\n",
    "fsize = 80 # font size\n",
    "frot = 0 # rotation of ticks\n",
    "\n",
    "temp_proj = temp_proj_geo\n",
    "    \n",
    "# North-South colouring\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_ns, cmap=cm.coolwarm_r, s=5)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "cbar = plt.colorbar(mapper_ns_temp,orientation='horizontal',cax=cax)\n",
    "cbar.set_label('Northing (km)',size=fsize)\n",
    "cbar.ax.tick_params(labelsize=fsize, rotation=frot)\n",
    "cbar.ax.text(s='More south',y=0.25, x=0.05, fontsize=fsize)\n",
    "cbar.ax.text(s='More north',y=0.25, x=0.75, fontsize=fsize)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir,file + '_ns' + suffix + '_' + tstamp + '.jpeg'),format='jpeg',bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# East-West colouring\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_ew, cmap=cm.spring, s=5)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "cbar = plt.colorbar(mapper_ew_temp,orientation='horizontal',cax=cax)\n",
    "cbar.set_label('Easting (km)',size=fsize)\n",
    "cbar.ax.tick_params(labelsize=fsize, rotation=frot)\n",
    "cbar.ax.text(s='More west',y=0.25, x=0.05, fontsize=fsize)\n",
    "cbar.ax.text(s='More east',y=0.25, x=0.75, fontsize=fsize)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir,file + '_ew' + suffix + '_' + tstamp + '.jpeg'),format='jpeg',bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "with open(os.path.join(img_dir,'randomstate_' + tstamp + '.txt'), 'w') as f:\n",
    "    f.write(str(st0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (phenotypes)\n",
    "Basically the same as geographical colouring... but with phenotypes! The main difference is that since the colourings are relative to sex, we need two for each variable (one male, one female). Other than that, you just select the dataset that contains your variables, the caption you'd like, the rounding value, and the percentiles where you'll cut off the measurements. Percentiles are symmetric, so selecting 5 will give you everything between the 5th and 95th percentiles.\n",
    "\n",
    "Filenames will have a timestamp. This is used to match the randomization state to the images generated, allowing for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset = ukbb_pheno_joined_height_res_blood\n",
    "\n",
    "# Values used for residual height\n",
    "#plot_var = 'Height_res'\n",
    "#caption = 'Age-adjusted residual height (cm)'\n",
    "\n",
    "#percentile = 1\n",
    "#round_val = 0\n",
    "\n",
    "# Values used for FEV1\n",
    "#plot_var = '3063_0_0'\n",
    "#caption = 'FEV1'\n",
    "\n",
    "#percentile = 1\n",
    "#round_val = 1\n",
    "\n",
    "# Values used for blood phenotypes\n",
    "\n",
    "#plot_var = 'neutrophill_count'\n",
    "#caption = 'Neutrophil count (10^9 cells/L)'\n",
    "\n",
    "#plot_var = 'basophill_count'\n",
    "#caption = 'Basophil count (10^9 cells/L)'\n",
    "\n",
    "#plot_var = 'eosinophill_count'\n",
    "#caption = 'Eosinophil count (10^9 cells/L)'\n",
    "\n",
    "#plot_var = 'leukocyte_count'\n",
    "#caption = 'Leukocyte count (10^9 cells/L)'\n",
    "\n",
    "plot_var = 'erythrocyte_count'\n",
    "caption = 'Erythrocyte count (10^12 cells/Litre)'\n",
    "\n",
    "percentile = 5\n",
    "round_val = 1\n",
    "base_val = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the indices of the sexes and create a dataset for each one\n",
    "has_data_f = dset.loc[((np.isnan(dset[plot_var])==False) & (dset['sex']=='0'))].index\n",
    "has_data_m = dset.loc[((np.isnan(dset[plot_var])==False) & (dset['sex']=='1'))].index\n",
    "\n",
    "has_data_f_df = dset.iloc[has_data_f]\n",
    "has_data_m_df = dset.iloc[has_data_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the projection dataset and subset it\n",
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections/'\n",
    "fname = 'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511'\n",
    "\n",
    "temp_proj=np.loadtxt(os.path.join(proj_dir,fname))\n",
    "temp_proj_f=temp_proj[has_data_f]\n",
    "temp_proj_m=temp_proj[has_data_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the KD tree objects\n",
    "kd_obj_f = scipy.spatial.KDTree(temp_proj_f)\n",
    "kd_obj_m = scipy.spatial.KDTree(temp_proj_m)\n",
    "\n",
    "temp_list_m = has_data_m_df[plot_var].values.tolist()#[t[0] for t in temp_list if t[1]=='1']\n",
    "temp_list_f = has_data_f_df[plot_var].values.tolist()#[t[0] for t in temp_list if t[1]=='0']\n",
    "\n",
    "females = has_data_f_df\n",
    "males = has_data_m_df\n",
    "\n",
    "dset_list_f = females[plot_var].values.tolist()\n",
    "dset_list_m = males[plot_var].values.tolist()\n",
    "\n",
    "dset_list_f = [round(d, round_val) for d in dset_list_f]\n",
    "dset_list_m = [round(d, round_val) for d in dset_list_m]\n",
    "\n",
    "min_m = np.nanpercentile(np.array(dset_list_m), percentile)\n",
    "max_m = np.nanpercentile(np.array(dset_list_m), 100-percentile)\n",
    "min_f = np.nanpercentile(np.array(dset_list_f), percentile)\n",
    "max_f = np.nanpercentile(np.array(dset_list_f), 100-percentile)\n",
    "\n",
    "num_bins_f = (max_f - min_f)/0.1 + 1\n",
    "num_bins_m = (max_m - min_m)/0.1 + 1\n",
    "\n",
    "alpha_vals = 0.6\n",
    "print('Min (F): ' + str(min_f) + ', Min (F): ' + str(max_f) + ', Bins: ' + str(num_bins_f))\n",
    "print('Min (M): ' + str(min_m) + ', Max (M): ' + str(max_m) + ', Bins: ' + str(num_bins_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random seed and store it for reproducibility\n",
    "np.random.seed(None)\n",
    "st0 = np.random.get_state()\n",
    "\n",
    "# Initialize lists of colouring values\n",
    "temp_colours_f = []\n",
    "temp_colours_m = []\n",
    "temp_colours_permuted_f = []\n",
    "temp_colours_permuted_m = []\n",
    "temp_alpha_f = []\n",
    "temp_alpha_m = []\n",
    "\n",
    "# Prepare the colouring (females)\n",
    "for h in dset_list_f:\n",
    "    # Unknown value - make it transparent and add an arbitrary value\n",
    "    if np.isnan(h):\n",
    "        temp_colours_f.append(np.mean([min_f, max_f]))\n",
    "        temp_alpha_f.append(0)\n",
    "    elif h < min_f:\n",
    "        temp_colours_f.append(min_f)\n",
    "        temp_alpha_f.append(alpha_vals)\n",
    "    elif h > max_f:\n",
    "        temp_colours_f.append(max_f)\n",
    "        temp_alpha_f.append(alpha_vals)\n",
    "    else:\n",
    "        temp_colours_f.append(h)\n",
    "        temp_alpha_f.append(alpha_vals)\n",
    "        \n",
    "# Permute the colouring (females)\n",
    "for t in range(0, temp_proj_f.shape[0]):\n",
    "    nn_index = np.random.choice(kd_obj_f.query(temp_proj_f[t],10)[1][1:])\n",
    "    temp_colours_permuted_f.append(temp_colours_f[nn_index])\n",
    "    \n",
    "norm_f = matplotlib.colors.Normalize(vmin=min_f, vmax=max_f, clip=False)\n",
    "mapper_f = cm.ScalarMappable(norm=norm_f, cmap=cm.coolwarm)\n",
    "\n",
    "colours_f = []\n",
    "    \n",
    "for i in range(0, len(temp_colours_f)):\n",
    "    colours_f.append(mapper_f.to_rgba(temp_colours_permuted_f[i], alpha=temp_alpha_f[i]))\n",
    "    \n",
    "mapper_f_temp = mapper_f\n",
    "mapper_f_temp._A = []\n",
    "\n",
    "# Prepare the colouring (males)\n",
    "for h in dset_list_m:\n",
    "    # Unknown value - make it transparent and add an arbitrary value\n",
    "    if np.isnan(h):\n",
    "        temp_colours_m.append(np.mean([min_m, max_m]))\n",
    "        temp_alpha_m.append(0)\n",
    "    elif h < min_m:\n",
    "        temp_colours_m.append(min_m)\n",
    "        temp_alpha_m.append(alpha_vals)\n",
    "    elif h > max_m:\n",
    "        temp_colours_m.append(max_m)\n",
    "        temp_alpha_m.append(alpha_vals)\n",
    "    else:\n",
    "        temp_colours_m.append(h)\n",
    "        temp_alpha_m.append(alpha_vals)\n",
    "\n",
    "# Permute the colouring (males)\n",
    "for t in range(0, temp_proj_m.shape[0]):\n",
    "    nn_index = np.random.choice(kd_obj_m.query(temp_proj_m[t],10)[1][1:])\n",
    "    temp_colours_permuted_m.append(temp_colours_m[nn_index])\n",
    "        \n",
    "norm_m = matplotlib.colors.Normalize(vmin=min_m, vmax=max_m, clip=False)\n",
    "mapper_m = cm.ScalarMappable(norm=norm_m, cmap=cm.coolwarm)\n",
    "\n",
    "colours_m = []\n",
    "    \n",
    "for i in range(0, len(temp_colours_m)):\n",
    "    colours_m.append(mapper_m.to_rgba(temp_colours_permuted_m[i], alpha=temp_alpha_m[i]))\n",
    "    \n",
    "mapper_m_temp = mapper_m\n",
    "mapper_m_temp._A = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tstamp = ''.join([str(t) for t in time.gmtime()[0:6]])\n",
    "\n",
    "out_dir = '/Volumes/Stockage/alex/ukbb_images/other/sandbox'\n",
    "fname = 'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511_' + tstamp\n",
    "size = 20\n",
    "fsize = 80 #font size\n",
    "\n",
    "# Female phenotypes\n",
    "temp_proj = temp_proj_f\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_f, cmap=cm.coolwarm, s=size)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "cbar = plt.colorbar(mapper_f_temp,orientation='horizontal',cax=cax)\n",
    "cbar.ax.tick_params(labelsize=fsize)\n",
    "cbar.set_label(caption,size=fsize)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "fig.savefig(os.path.join(out_dir, fname.replace('.','')+'_'+plot_var+'_pct'+str(percentile)+'_f.jpeg'),format='jpeg',\n",
    "           bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Male phenotypes\n",
    "#temp_proj = proj[indices_of_population_sex['1']]\n",
    "temp_proj = temp_proj_m\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_m, cmap=cm.coolwarm, s=size)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "cbar = plt.colorbar(mapper_m_temp,orientation='horizontal',cax=cax)\n",
    "cbar.ax.tick_params(labelsize=fsize)\n",
    "cbar.set_label(caption,size=fsize)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "fig.savefig(os.path.join(out_dir, fname.replace('.','')+'_'+plot_var+'_pct'+str(percentile)+'_m.jpeg'),format='jpeg',\n",
    "           bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "with open(os.path.join(out_dir,'randomstate_' + tstamp + '.txt'), 'w') as f:\n",
    "    f.write(str(st0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots\n",
    "The boxplots are straightforward - the only changes are basically in formatting, axes, and labelling for each sex and variable. P-values are from comparisons between the White British ethnic group and others, with a Bonferroni correction for 12 comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The order the boxes will appear.\n",
    "order_list = ['British','Irish','Any other white background','White and Black African','White and Black Caribbean',\n",
    "                     'White and Asian','African','Caribbean','Any other Black background',\n",
    "                     'Chinese','Indian','Pakistani','Bangladeshi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of the variables for which we'll create boxplots\n",
    "var_list = ['Height_res','3063_0_0','neutrophill_count','basophill_count','eosinophill_count','leukocyte_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Captions/labels\n",
    "label_dict = {'Height_res':'Age-adjusted residual height (cm)',\n",
    "              '3063_0_0':'FEV1',\n",
    "              'neutrophill_count':'Neutrophil count (10^9 cells/L)',\n",
    "              'basophill_count':'Basophil count (10^9 cells/L)',\n",
    "              'eosinophill_count':'Eosinophil count (10^9 cells/L)',\n",
    "              'leukocyte_count':'Leukocyte count (10^9 cells/L)'}\n",
    "# Plot titles\n",
    "title_dict = {'Height_res':'Residual height',\n",
    "              '3063_0_0':'FEV1',\n",
    "              'neutrophill_count':'Neutrophil count',\n",
    "              'basophill_count':'Basophil count',\n",
    "              'eosinophill_count':'Eosinophil count',\n",
    "              'leukocyte_count':'Leukocyte count'}\n",
    "# Offsets used for labelling p-values\n",
    "xy_dict = {'Height_res':{'F':19.9,'M':19.9},\n",
    "          '3063_0_0':{'F':4,'M':5.5},\n",
    "          'neutrophill_count':{'F':12.2,'M':13},\n",
    "          'basophill_count':{'F':8.2,'M':8.2},\n",
    "          'eosinophill_count':{'F':4.2,'M':4},\n",
    "          'leukocyte_count':{'F':12.2,'M':12.2}}\n",
    "# Ranges for the x-axis of the boxplots\n",
    "xlim_dict = {'Height_res':{'F':[-25,30.2],'M':[-25,30.2]},\n",
    "             '3063_0_0':{'F':[0,5],'M':[0,6.8]},\n",
    "             'neutrophill_count':{'F':[0,15],'M':[0,15.7]},\n",
    "             'basophill_count':{'F':[0,10],'M':[0,10]},\n",
    "             'eosinophill_count':{'F':[0,5.1],'M':[0,4.8]},\n",
    "             'leukocyte_count':{'F':[0,15],'M':[0,15]}}\n",
    "# Full word for sex (instead of M/F)\n",
    "sex_dict = {'F':'Female', 'M':'Male'}\n",
    "# Translate between 0/F and 1/M\n",
    "sex_dict_code = {'F':'0', 'M':'1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the dataset with text labels for ethnicity\n",
    "dset = ukbb_pheno_joined_height_res_blood_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the output directory\n",
    "img_dir = '/Volumes/Stockage/alex/ukbb_images/other/sandbox'\n",
    "\n",
    "# This double loop goes through every variable for each sex\n",
    "for v in var_list:\n",
    "    for sex in ['F','M']:\n",
    "        # First calculate the p-values relative to the British population, with a Bonferroni correction\n",
    "        set1 = dset.loc[((dset['eth_txt']=='British') & (dset['sex']==sex_dict_code[sex]))]\n",
    "        pv_list = list()\n",
    "\n",
    "        # For each non-British ethnicity, compare the differences and retrieve the p-value\n",
    "        for eth in eth_list[1:]:\n",
    "            set2 = dset.loc[((dset['eth_txt']==eth) & (dset['sex']==sex_dict_code[sex]))]\n",
    "            pv_list.append(format(ttest_ind(set1[v], set2[v], nan_policy='omit').pvalue,'.2e'))\n",
    "\n",
    "        # From here we're just creating and formatting the boxplot\n",
    "        fsize=30\n",
    "        fig, ax = plt.subplots(figsize=(30,20))\n",
    "        sns.boxplot(ax = ax, orient='h',\n",
    "                    palette = color_dict_ukbb,\n",
    "                    y = 'eth_txt',\n",
    "                    x = v,\n",
    "                    showfliers=False,\n",
    "                    order = order_list,\n",
    "                   data = dset.loc[(dset['sex']==sex_dict_code[sex])])\n",
    "\n",
    "        # Annotate with p-values\n",
    "        for pv in range(0,len(pv_list)):\n",
    "            if np.float(pv_list[pv])<0.05/12:\n",
    "                ax.annotate(s='* (p-val: '+pv_list[pv]+')',xy=(xy_dict[v][sex],pv+1),size=30)\n",
    "            else:\n",
    "                ax.annotate(s='  (pval: ' + pv_list[pv]+')',xy=(xy_dict[v][sex],pv+1),size=30)\n",
    "\n",
    "        # Axis limits, labels\n",
    "        ax.set_xlim(xlim_dict[v][sex])        \n",
    "        ax.set_xlabel(label_dict[v])\n",
    "        ax.set_ylabel('Ethnic background')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=45)\n",
    "        ax.set_title(title_dict[v] + ' by ethnic background (' + sex_dict[sex] + ')')\n",
    "\n",
    "        # Font sizes\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                      ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            item.set_fontsize(30)\n",
    "\n",
    "        # Specify a filename giving the variable and sex, and save\n",
    "        fname = 'boxplot_' + v + '_' + sex\n",
    "        fig.savefig(os.path.join(img_dir,fname + '.jpeg'),format='jpeg',bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print('Created boxplot for ' + title_dict[v] + ' for ' + sex_dict[sex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate a bunch of images to permute them\n",
    "\n",
    "proj_dir = '/Volumes/Stockage/alex/ukbb_projections'\n",
    "\n",
    "#proj_list = ['UKBB_UMAP_PC2_NN15_MD0.5_2018328183825','UKBB_UMAP_PC3_NN15_MD0.5_2018328183825',\n",
    "#             'UKBB_UMAP_PC4_NN15_MD0.5_2018328183825','UKBB_UMAP_PC6_NN15_MD0.5_2018328183825',\n",
    "#             'UKBB_UMAP_PC7_NN15_MD0.5_2018328183825','UKBB_UMAP_PC8_NN15_MD0.5_2018329175935',\n",
    "#             'UKBB_UMAP_PC9_NN15_MD0.5_2018328183825','UKBB_UMAP_PC5_NN15_MD0.5_2018329175935',\n",
    "#             'UKBB_UMAP_PC10_NN15_MD0.5_2018328174511','UKBB_UMAP_PC14_NC2_NN15_MD0.5_20184415956',\n",
    "#             'UKBB_UMAP_PC15_NC2_NN15_MD0.5_20184181602','UKBB_UMAP_PC20_NC2_NN15_MD0.5_2018454111',\n",
    "#             'UKBB_UMAP_PC25_NC2_NN15_MD0.5_2018454111','UKBB_UMAP_PC30_NC2_NN15_MD0.5_2018454111',\n",
    "#             'UKBB_UMAP_PC35_NC2_NN15_MD0.5_2018454111','UKBB_UMAP_PC40_NC2_NN15_MD0.5_2018454111']\n",
    "proj_list = ['UKBB_UMAP_PC9_NN15_MD0.5_2018329175935']\n",
    "\n",
    "for file in proj_list:\n",
    "    print(\"Loading \" + file)\n",
    "    temp_proj = np.loadtxt(os.path.join(proj_dir,file))\n",
    "\n",
    "    # indices of points that have geographical coordinates\n",
    "    has_data = ukbb_df_joined2.loc[(np.isnan(ukbb_df_joined2.northing_orig)==False)].index\n",
    "\n",
    "    # Subset coordinate array such that it's only observations with data\n",
    "    temp_proj_geo = temp_proj[has_data]\n",
    "\n",
    "    # Make it into a dataframe and make a list of the coordinates, where they exist\n",
    "    has_data_df = ukbb_df_joined2.iloc[has_data]\n",
    "    has_data_coords = has_data_df[['northing_filled','easting_filled']].values.tolist()\n",
    "    \n",
    "    # Create K-D tree object\n",
    "    kd_obj = scipy.spatial.KDTree(temp_proj_geo)\n",
    "    \n",
    "    # Test out permutations with nearest neighbours. We'll swap in values of randomly select neighbours.\n",
    "    # Those with zero values are invalid, so we make them invisible (alpha value of zero)\n",
    "    temp_colours_ns = []\n",
    "    temp_colours_ew = []\n",
    "\n",
    "    temp_alpha = []\n",
    "\n",
    "    ns_min = 100000\n",
    "    ns_max = 700000\n",
    "    ew_min = 200000\n",
    "    ew_max = 600000\n",
    "    alpha_vals = 0.6\n",
    "\n",
    "    round_val = -4\n",
    "    sd=50000\n",
    "    base=50000 # round to nearest however many thousand metres\n",
    "\n",
    "    for u in has_data_coords:\n",
    "        no_geo = False\n",
    "        # Set alpha to zero for unknown geo values\n",
    "        if u[0]<=0 or u[1]<=0:\n",
    "            no_geo = True\n",
    "            temp_alpha.append(np.float(0))\n",
    "            temp_colours_ns.append((northing_mean))\n",
    "            temp_colours_ew.append((easting_mean))\n",
    "\n",
    "        if no_geo==False:\n",
    "            if u[0] < ns_min:\n",
    "                temp_colours_ns.append(ns_min)\n",
    "            elif u[0] > ns_max:\n",
    "                temp_colours_ns.append(ns_max)\n",
    "            else:\n",
    "                temp_colours_ns.append(round(u[0] + np.random.normal(0,sd),round_val))\n",
    "\n",
    "            if u[1] < ew_min:\n",
    "                temp_colours_ew.append(ew_min)\n",
    "            elif u[1] > ew_max:\n",
    "                temp_colours_ew.append(ew_max)\n",
    "            else:\n",
    "                temp_colours_ew.append(round(u[1] + np.random.normal(0,sd),round_val))\n",
    "\n",
    "            temp_alpha.append(np.float(alpha_vals))\n",
    "    \n",
    "    # Rounding for labels \n",
    "    temp_colours_ns = [t/1000 for t in temp_colours_ns]\n",
    "    temp_colours_ew = [t/1000 for t in temp_colours_ew]\n",
    "\n",
    "    ns_min = ns_min/1000\n",
    "    ns_max = ns_max/1000\n",
    "    ew_min = ew_min/1000\n",
    "    ew_max = ew_max/1000\n",
    "    \n",
    "    print('Creating random state')\n",
    "    # Create a random seed and store it for reproducibility\n",
    "    np.random.seed(None)\n",
    "    \n",
    "    st0 = np.random.get_state()\n",
    "\n",
    "    temp_colours_permuted_ns = []\n",
    "    temp_colours_permuted_ew = []\n",
    "    index_list = []\n",
    "\n",
    "    print('Randomly sampling colours')\n",
    "    # Now that we have our colouring values we can sample them randomly (since neighbours exist now)\n",
    "    for t in range(0, temp_proj_geo.shape[0]):\n",
    "        # Randomly select an index from a neighbour\n",
    "        nn_index = np.random.choice(kd_obj.query(temp_proj_geo[t],10)[1][1:])\n",
    "        index_list.append(nn_index)\n",
    "        temp_colours_permuted_ns.append(temp_colours_ns[nn_index])\n",
    "        temp_colours_permuted_ew.append(temp_colours_ew[nn_index])\n",
    "    \n",
    "    print('Creating colour maps')\n",
    "    norm_ns = matplotlib.colors.Normalize(vmin=ns_min, vmax=ns_max, clip=False)\n",
    "    norm_ew = matplotlib.colors.Normalize(vmin=ew_min, vmax=ew_max, clip=False)\n",
    "    mapper_ns = cm.ScalarMappable(norm=norm_ns, cmap=cm.coolwarm_r)\n",
    "    mapper_ew = cm.ScalarMappable(norm=norm_ew, cmap=cm.spring)\n",
    "    \n",
    "    colours_ns = []\n",
    "    colours_ew = []\n",
    "\n",
    "    print('Adding random colours')\n",
    "    for i in range(0, temp_proj_geo.shape[0]):\n",
    "        colours_ns.append(mapper_ns.to_rgba(temp_colours_permuted_ns[i], alpha=temp_alpha[i]))\n",
    "        colours_ew.append(mapper_ew.to_rgba(temp_colours_permuted_ew[i], alpha=temp_alpha[i]))\n",
    "        \n",
    "    # Not totally sure why I have to do this but here we are\n",
    "    mapper_ns_temp = mapper_ns\n",
    "    mapper_ew_temp = mapper_ew\n",
    "\n",
    "    mapper_ns_temp._A = []\n",
    "    mapper_ew_temp._A = []\n",
    "    \n",
    "    # Create a timestamp to relate images to their random imputation\n",
    "    tstamp = ''.join([str(t) for t in time.gmtime()[0:6]])\n",
    "\n",
    "    img_dir = '/Volumes/Stockage/alex/ukbb_images/other/sandbox/geo_impute'\n",
    "    suffix = '_permuted_10nn_sd' + str(sd) + '_base' + str(base)\n",
    "    fsize = 80 # font size\n",
    "    frot = 0 # rotation of ticks\n",
    "\n",
    "    temp_proj = temp_proj_geo\n",
    "    \n",
    "    print('Generating image')\n",
    "\n",
    "    # North-South colouring\n",
    "    fig = plt.figure(figsize=(50,50))\n",
    "    ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "    ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_ns, cmap=cm.coolwarm_r, s=5)\n",
    "    #divider = make_axes_locatable(ax)\n",
    "    #cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "    #cbar = plt.colorbar(mapper_ns_temp,orientation='horizontal',cax=cax)\n",
    "    #cbar.set_label('Northing (km)',size=fsize)\n",
    "    #cbar.ax.tick_params(labelsize=fsize, rotation=frot)\n",
    "    #cbar.ax.text(s='More south',y=0.25, x=0.05, fontsize=fsize)\n",
    "    #cbar.ax.text(s='More north',y=0.25, x=0.75, fontsize=fsize)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.savefig(os.path.join(img_dir,file + '_ns' + suffix + '_' + tstamp + '.jpeg'),format='jpeg',bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # East-West colouring\n",
    "    fig = plt.figure(figsize=(50,50))\n",
    "    ax = fig.add_subplot(111, aspect=1)\n",
    "\n",
    "    ax.scatter(temp_proj[:,0], temp_proj[:,1], c=colours_ew, cmap=cm.spring, s=5)\n",
    "\n",
    "    #divider = make_axes_locatable(ax)\n",
    "    #cax = divider.append_axes('bottom',size='5%',pad=0.05)\n",
    "\n",
    "    #cbar = plt.colorbar(mapper_ew_temp,orientation='horizontal',cax=cax)\n",
    "    #cbar.set_label('Easting (km)',size=fsize)\n",
    "    #cbar.ax.tick_params(labelsize=fsize, rotation=frot)\n",
    "    #cbar.ax.text(s='More west',y=0.25, x=0.05, fontsize=fsize)\n",
    "    #cbar.ax.text(s='More east',y=0.25, x=0.75, fontsize=fsize)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.savefig(os.path.join(img_dir,file + '_ew' + suffix + '_' + tstamp + '.jpeg'),format='jpeg',bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    with open(os.path.join(img_dir,'randomstate_' + tstamp + '.txt'), 'w') as f:\n",
    "        f.write(str(st0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
